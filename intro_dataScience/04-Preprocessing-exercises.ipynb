{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing: Exercises\n",
    "\n",
    "* Al√≠pio Jorge, Introduction to Data Science, 2021 *\n",
    "\n",
    "1. A fashion company bought two major shops in town and needs to merge product data for feeding a customer intelligence application. In one of the shops the database contains the attributes \n",
    "- `<prod_id, prod_category, launch_date, items_sold, price_per_item>` \n",
    "The other shop has a database with\n",
    "- `<product_id, category_of_product, country_of_origin, value_sold>` \n",
    "Identify at least 5 potential problems and respective solutions when merging the data bases.\n",
    "2. A company is developing an application for tracking customers inside a shopping mall from the bluetooth signals of their mobile phones. The dataframe below simulates a set of records for customer 'c101' in a succession of time stamps. For each moment, the device identifies the floor of the mall where 'c101' is. But when 'c101' changes floor by using the staircase, the records flounder. How can we solve the problem with the 'floor' attribute? Propose a simple algorithmic method for fixing it? What kind of data preprocessing operation is it? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custid</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>floor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c101</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c101</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c101</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c101</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c101</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c101</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>c101</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>c101</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>c101</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>c101</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>c101</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>c101</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>c101</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>c101</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>c101</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>c101</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>c101</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   custid  timestamp  floor\n",
       "0    c101          1      1\n",
       "1    c101          2      1\n",
       "2    c101          3      1\n",
       "3    c101          4      0\n",
       "4    c101          5      1\n",
       "5    c101          6      0\n",
       "6    c101          7      1\n",
       "7    c101          8      0\n",
       "8    c101          9      0\n",
       "9    c101         10      1\n",
       "10   c101         11      0\n",
       "11   c101         12      0\n",
       "12   c101         13      0\n",
       "13   c101         14      0\n",
       "14   c101         15      0\n",
       "15   c101         16      0\n",
       "16   c101         17      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "floor=np.array([1,1,1,0,1,0,1,0,0,1,0,0,0,0,0,0,0])\n",
    "custid=np.array(['c101']*len(floor))\n",
    "timst=np.array([i for i in range(len(floor))])+1\n",
    "d=pd.DataFrame({'custid':custid,'timestamp':timst,'floor':floor})\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Consider the following array `<8,12,4,12,NA,9,7,1,15,NA,12,13,7,NA,23,12,NA,9,8,5,NA,21,13,NA,12,3,11,NA,10,6>`\n",
    "Compare different methods of data imputation and their effect on the mean and standard deviation of the array. Consider the methods:\n",
    "- replace by a constant value (e.g. -1)\n",
    "- replace by the most frequent value\n",
    "- replace by the mean\n",
    "- replace each NA by a value sampled from the distribution of observed values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Consider the array above but without the NAs (replaced by some other value) and normalize the array by using:\n",
    "- min-max normalization\n",
    "- z-score normalization\n",
    "5. Now the values $<5,12,23,35>$ have to be added. Normalize them with each of the approaches.\n",
    "6. Use the iris data set and randomly delete 15 values from the first column and pretend they are missing data. Consider different imputation approaches to 'guess' the missing values. Calculate the Mean Average Error of each approach by using the hidden values and the imputed values. Try the approaches:\n",
    "- Replace by the mean of the column.\n",
    "- Replace by the mean of the respective class.\n",
    "- Replace by the value of the nearest neighbor.\n",
    "Next you have some code with solutions for the two first taks. If you know pandas and python try to solve them before you look at the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of column ignoring NaN=  5.8496296296296295\n",
      "Std of column ignoring NaN=  0.8203769751427129\n",
      "Mean of column after imputing simple mean=  5.849629629629629\n",
      "Std of column fter imputing simple mean=  0.7782779344230932\n",
      "The mean for class  versicolor  is  5.9229629629629645\n",
      "imputing 5.924429629629629 in case 73 of class versicolor\n",
      "imputing 6.510962962962963 in case 104 of class virginica\n",
      "imputing 5.924429629629629 in case 78 of class versicolor\n",
      "imputing 6.510962962962963 in case 119 of class virginica\n",
      "imputing 5.114962962962963 in case 38 of class setosa\n",
      "imputing 6.510962962962963 in case 129 of class virginica\n",
      "imputing 5.114962962962963 in case 16 of class setosa\n",
      "imputing 5.924429629629629 in case 77 of class versicolor\n",
      "imputing 5.114962962962963 in case 42 of class setosa\n",
      "imputing 6.510962962962963 in case 140 of class virginica\n",
      "imputing 5.924429629629629 in case 66 of class versicolor\n",
      "imputing 5.114962962962963 in case 12 of class setosa\n",
      "imputing 5.114962962962963 in case 45 of class setosa\n",
      "imputing 6.510962962962963 in case 144 of class virginica\n",
      "imputing 5.924429629629629 in case 80 of class versicolor\n",
      "Mean of column after imputing class mean=  5.849678518518518\n",
      "Std of column fter imputing class mean=  0.7990450165349776\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "iris = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv')\n",
    "# get first column as an array\n",
    "fc=np.array(iris[['sepal_length']])\n",
    "# we need the sample method from the random library\n",
    "import random\n",
    "# todel is a sample of 15 values\n",
    "todel=random.sample(range(0,len(fc)),15)\n",
    "# keep the original values in 'keep'\n",
    "fc_nan=fc\n",
    "# insert nan in the 15 randomly chosen positions\n",
    "fc_nan[todel]=np.nan\n",
    "# calculate the mean of the of the other values\n",
    "simplemean=np.nanmean(fc_nan)\n",
    "print(\"Mean of column ignoring NaN= \",simplemean)\n",
    "print(\"Std of column ignoring NaN= \",np.nanstd(fc_nan))\n",
    "# replace the positions with the mean (imputation 1)\n",
    "fc_imp1=fc_nan\n",
    "fc_imp1[todel]=simplemean\n",
    "print(\"Mean of column after imputing simple mean= \",np.mean(fc_imp1))\n",
    "print(\"Std of column fter imputing simple mean= \",np.nanstd(fc_imp1))\n",
    "# Imputation 2, replace by the mean of the respective class\n",
    "# Each of the positions has a different class. Let do it for the first one\n",
    "# go to iris and use loc (localizer) to fetch the line with number todel[0] and column (species)\n",
    "classname=iris.loc[todel[0],'species']\n",
    "# now calculate the mean only for this class\n",
    "# get the indexes of the cases for that class\n",
    "class_idx=np.where(iris.species=='versicolor')\n",
    "# calculate the mean of fc_nan (the one with the missing values) for that class only\n",
    "mean_class1=np.nanmean(fc_nan[class_idx])\n",
    "print(\"The mean for class \",classname,\" is \",mean_class1)\n",
    "# impute the mean of the class\n",
    "fc_imp2=fc_nan\n",
    "fc_imp1[todel[0]]=mean_class1\n",
    "# this was just for one value. We could have done this for all the values in one go\n",
    "# get the means for the 3 classes and put them in one array\n",
    "# the initial array for the means. zeros for now\n",
    "class_means=np.zeros(3)\n",
    "# build a list with class names\n",
    "class_names=[0]*3\n",
    "for p in [(0,0),(1,50),(2,100)]: \n",
    "    class_names[p[0]]=iris.loc[p[1],'species']\n",
    "# Now get the means and put them in the class_means array\n",
    "for i in range(0,3):\n",
    "    current_class=class_names[i]\n",
    "    class_idx=np.where(iris.species==current_class)\n",
    "    class_means[i]=np.nanmean(fc_nan[class_idx])\n",
    "# Now we have the means we can process all the NaN\n",
    "for i in range(0,15):\n",
    "    case_idx=todel[i]\n",
    "    class_of_case=iris.loc[case_idx,'species']\n",
    "    # impute case with mean of class\n",
    "    fc_imp2[case_idx]=class_means[class_names.index(class_of_case)]\n",
    "    print(\"imputing\",class_means[class_names.index(class_of_case)],\"in case\", case_idx, \"of class\", class_of_case)\n",
    "# What was the impact in mean and std?\n",
    "print(\"Mean of column after imputing class mean= \",np.mean(fc_imp2))\n",
    "print(\"Std of column fter imputing class mean= \",np.nanstd(fc_imp2))\n",
    "# to replace with the mean of nearest neighbor we need to build the distance matrix for the examples\n",
    "# find the nearest neighbor for each of the missing cases, get its value and then impute\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Consider the dataset of cardiac patients that you can download in moodle.Examine this data and decide what steps of preprocessing may be useful (and why). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
